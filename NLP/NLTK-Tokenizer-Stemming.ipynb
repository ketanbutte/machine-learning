{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0b6d65-cc2e-40ef-8dd4-b55501ce3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2908ffe4-f277-47d9-90f6-2ae826c75609",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "Kalki 2898 AD (pronounced [kə.l.kɪ]) is a 2024 Indian Telugu-language epic science fiction film\n",
    "directed by Nag Ashwin and produced by Vyjayanthi Movies. \n",
    "The film stars Amitabh Bachchan, Kamal Haasan, Prabhas, Deepika Padukone and Disha Patani. \n",
    "Inspired by Hindu scriptures, it is the first instalment in a planned Kalki Cinematic Universe. \n",
    "Set in a post-apocalyptic world in the year 2898 AD, the film follows a select group on a mission to save Kalki, the unborn child of SUM-80, a lab subject.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2910475b-a522-48ec-98ca-e2b4e137f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1729dbe8-5325-4266-89a6-faf4e38f71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "295742e0-976a-46e5-baa4-b8e0186252d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kalki 2898 AD (pronounced [kə.l.kɪ]) is a 2024 Indian Telugu-language epic science fiction film\n",
      "directed by Nag Ashwin and produced by Vyjayanthi Movies.\n",
      "\n",
      "The film stars Amitabh Bachchan, Kamal Haasan, Prabhas, Deepika Padukone and Disha Patani.\n",
      "\n",
      "Inspired by Hindu scriptures, it is the first instalment in a planned Kalki Cinematic Universe.\n",
      "\n",
      "Set in a post-apocalyptic world in the year 2898 AD, the film follows a select group on a mission to save Kalki, the unborn child of SUM-80, a lab subject.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8af40e3-ff86-4345-bf33-4b4e2f805d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "\n",
    "#paragraph-->words\n",
    "#sentence --> words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c58fe40-7b46-4860-898a-3c5a5c8d83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b917a0-e2d7-4485-b03a-a1f91e1e7e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kalki',\n",
       " '2898',\n",
       " 'AD',\n",
       " '(',\n",
       " 'pronounced',\n",
       " '[',\n",
       " 'kə.l.kɪ',\n",
       " ']',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " '2024',\n",
       " 'Indian',\n",
       " 'Telugu-language',\n",
       " 'epic',\n",
       " 'science',\n",
       " 'fiction',\n",
       " 'film',\n",
       " 'directed',\n",
       " 'by',\n",
       " 'Nag',\n",
       " 'Ashwin',\n",
       " 'and',\n",
       " 'produced',\n",
       " 'by',\n",
       " 'Vyjayanthi',\n",
       " 'Movies',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a6d50ce-b710-4d0c-8159-e10ec2783255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kalki', '2898', 'AD', '(', 'pronounced', '[', 'kə.l.kɪ', ']', ')', 'is', 'a', '2024', 'Indian', 'Telugu-language', 'epic', 'science', 'fiction', 'film', 'directed', 'by', 'Nag', 'Ashwin', 'and', 'produced', 'by', 'Vyjayanthi', 'Movies', '.']\n",
      "28\n",
      "['The', 'film', 'stars', 'Amitabh', 'Bachchan', ',', 'Kamal', 'Haasan', ',', 'Prabhas', ',', 'Deepika', 'Padukone', 'and', 'Disha', 'Patani', '.']\n",
      "17\n",
      "['Inspired', 'by', 'Hindu', 'scriptures', ',', 'it', 'is', 'the', 'first', 'instalment', 'in', 'a', 'planned', 'Kalki', 'Cinematic', 'Universe', '.']\n",
      "17\n",
      "['Set', 'in', 'a', 'post-apocalyptic', 'world', 'in', 'the', 'year', '2898', 'AD', ',', 'the', 'film', 'follows', 'a', 'select', 'group', 'on', 'a', 'mission', 'to', 'save', 'Kalki', ',', 'the', 'unborn', 'child', 'of', 'SUM-80', ',', 'a', 'lab', 'subject', '.']\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(word_tokenize(sentence))\n",
    "    print(len(word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40a6dc7e-62f1-4818-b36f-e38839991cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a7f73b7-4938-4590-8e12-3d0f2c382d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kalki', '2898', 'AD', '(', 'pronounced', '[', 'kə', '.', 'l', '.', 'kɪ', '])', 'is', 'a', '2024', 'Indian', 'Telugu', '-', 'language', 'epic', 'science', 'fiction', 'film', 'directed', 'by', 'Nag', 'Ashwin', 'and', 'produced', 'by', 'Vyjayanthi', 'Movies', '.']\n",
      "33\n",
      "['The', 'film', 'stars', 'Amitabh', 'Bachchan', ',', 'Kamal', 'Haasan', ',', 'Prabhas', ',', 'Deepika', 'Padukone', 'and', 'Disha', 'Patani', '.']\n",
      "17\n",
      "['Inspired', 'by', 'Hindu', 'scriptures', ',', 'it', 'is', 'the', 'first', 'instalment', 'in', 'a', 'planned', 'Kalki', 'Cinematic', 'Universe', '.']\n",
      "17\n",
      "['Set', 'in', 'a', 'post', '-', 'apocalyptic', 'world', 'in', 'the', 'year', '2898', 'AD', ',', 'the', 'film', 'follows', 'a', 'select', 'group', 'on', 'a', 'mission', 'to', 'save', 'Kalki', ',', 'the', 'unborn', 'child', 'of', 'SUM', '-', '80', ',', 'a', 'lab', 'subject', '.']\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(wordpunct_tokenize(sentence))\n",
    "    print(len(wordpunct_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf66a6d-39da-4b1f-8980-cc426a60e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf2319eb-b125-4df5-96b9-fae54c22f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "treebanktokenizer = TreebankWordDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d96d16c0-5a2d-4e79-8096-22ca0b9d6fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K a l k i   2 8 9 8   A D   (p r o n o u n c e d   [k ə . l . k ɪ])   i s   a   2 0 2 4   I n d i a n   T e l u g u - l a n g u a g e   e p i c   s c i e n c e   f i c t i o n   f i l m \n",
      " d i r e c t e d   b y   N a g   A s h w i n   a n d   p r o d u c e d   b y   V y j a y a n t h i   M o v i e s .   \n",
      " T h e   f i l m   s t a r s   A m i t a b h   B a c h c h a n,   K a m a l   H a a s a n,   P r a b h a s,   D e e p i k a   P a d u k o n e   a n d   D i s h a   P a t a n i .   \n",
      " I n s p i r e d   b y   H i n d u   s c r i p t u r e s,   i t   i s   t h e   f i r s t   i n s t a l m e n t   i n   a   p l a n n e d   K a l k i   C i n e m a t i c   U n i v e r s e .   \n",
      " S e t   i n   a   p o s t - a p o c a l y p t i c   w o r l d   i n   t h e   y e a r   2 8 9 8   A D,   t h e   f i l m   f o l l o w s   a   s e l e c t   g r o u p   o n   a   m i s s i o n   t o   s a v e   K a l k i,   t h e   u n b o r n   c h i l d   o f   S U M - 8 0,   a   l a b   s u b j e c t.\n"
     ]
    }
   ],
   "source": [
    "print(treebanktokenizer.tokenize(corpus))\n",
    "# print(len(treebanktokenizer.tokenize(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb050314-ec52-4fe2-b866-a66d4953aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abc06a-16ea-4301-a6b3-013b06131c7c",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7db7bb62-1d25-47de-a15a-daebce099d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"going\",\"eating\",\"historically\",\"generally\",\"dancing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "331dd1cc-3196-4573-8d5e-c6ad28c863f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "643b2463-e4f7-4c4b-98b4-7728bd2b0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming= PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d19552d6-bc25-4151-bc10-59d2296b27f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"Wording\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bec5770-2786-4341-93f1-d881d028a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going --> go\n",
      "eating --> eat\n",
      "historically --> histor\n",
      "generally --> gener\n",
      "dancing --> danc\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,\"-->\",stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "594a7a9d-39a2-4a71-b52e-c18c24b547c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " detailed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'detail'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b72c63-b358-430d-88c2-214a40b55456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " trying\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tri'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(input())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad10fa-acd6-4134-8073-99fc21c6d7ac",
   "metadata": {},
   "source": [
    "#### RegexStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e52f14b5-8db5-4d58-81ea-3001d827ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1eda110c-aaf4-4826-94b8-d5d5b594b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer(regexp=\"^ing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d99ecd9d-a731-4a05-8b63-4a8042a377e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'landing'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem(\"inglanding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48df7e2-379c-4a67-837b-81804b072b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17de212a-2279-472e-ae91-e448e4ef34cb",
   "metadata": {},
   "source": [
    "#### Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "96e79db8-9d07-48bc-a9f1-a094414a65b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3b748b7-9456-4d04-ba38-e0a5419b30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "560fbbfe-2e52-4e9b-be2a-139b667ca2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "eat\n",
      "histor\n",
      "general\n",
      "danc\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(snow_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c61e4-58fc-4268-a111-92fbd95c7258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
